{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bab03f6",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d66de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e5d60",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de39dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(fileName):\n",
    "    op = []\n",
    "    flag = 0\n",
    "    with open(fileName) as f: #open the .txt files\n",
    "        for i in f.readlines():\n",
    "            #specify when to start extracting the text\n",
    "            if i[:9] == \"*** START\":\n",
    "                flag = 1\n",
    "                continue\n",
    "            #specify when to stop extracting the text\n",
    "            if i[:7] == \"*** END\":\n",
    "                break\n",
    "            #extract the text\n",
    "            if flag == 1 and i != '\\n':\n",
    "                op.append(i[:-1].lower())\n",
    "    op = op[1:-2]\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50e940df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess both the files\n",
    "sh = preProcess('pg1661.txt')\n",
    "ja = preProcess('pg31100.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1981cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize the dataset\n",
    "rnd = np.random.RandomState(42)\n",
    "rnd.shuffle(sh)\n",
    "rnd.shuffle(ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d97966fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set testSize to 1000 for both the files\n",
    "testSize = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9c1b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing set\n",
    "trainSH = sh[:-testSize]\n",
    "testSH = sh[-testSize:]\n",
    "trainJA = ja[:-testSize]\n",
    "testJA = ja[-testSize:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f3f0d",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51890148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    #Initialization\n",
    "    def __init__(self):\n",
    "        #store a list of stopwords\n",
    "        self.stopWords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "        #set other params to None\n",
    "        self.words1 = None\n",
    "        self.words2 = None\n",
    "        self.count1 = None\n",
    "        self.count2 = None\n",
    "        self.prob1 = None\n",
    "        self.prob2 = None\n",
    "        self.alpha = None\n",
    "    \n",
    "    #Fitting the model\n",
    "    def fit(self, c1, c2, alpha = 1):\n",
    "        self.alpha = alpha #stores the smoothing factor\n",
    "        self.words1 = self.__getWords__(c1) #gets a list of all words belonging to class1\n",
    "        self.words2 = self.__getWords__(c2) #gets a list of all words belonging to class2\n",
    "        self.count1 = self.__getCount__(self.words1) #gets count of occurance of all words in class1\n",
    "        self.count2 = self.__getCount__(self.words2) #gets count of occurance of all words in class1\n",
    "        self.prob1 = self.__getProb__(self.count1) #gets probability of each word in class1\n",
    "        self.prob2 = self.__getProb__(self.count2) #gets probability of each word in class1\n",
    "    \n",
    "    #Predicting method\n",
    "    def predict(self, sentences):\n",
    "        self.pred = []\n",
    "        for sentence in sentences:\n",
    "            words = self.__clean__(sentence)\n",
    "            p1, p2 = 0, 0 #initialize probabilities to 0\n",
    "            for word in words:\n",
    "                #get probability if the word is present in the training set\n",
    "                if word in self.prob1:\n",
    "                    p1 += np.log(self.prob1[word])\n",
    "                if word in self.prob2:\n",
    "                    p2 += np.log(self.prob2[word])\n",
    "                #if the word is not present in the training set, add the smoothing factor\n",
    "                if word not in self.prob1:\n",
    "                    p1 += np.log(self.alpha / (len(self.prob1)))\n",
    "                if word not in self.prob2:\n",
    "                    p2 += np.log(self.alpha / (len(self.prob2)))\n",
    "            if p1 > p2:\n",
    "                self.pred.append(1)\n",
    "            else:\n",
    "                self.pred.append(0)\n",
    "        return self.pred\n",
    "    \n",
    "    #Helper clean method that removes stopwords and punctuation\n",
    "    def __clean__(self, sentence):\n",
    "        words = []\n",
    "        sentence = sentence.lower()\n",
    "        for word in sentence.split():\n",
    "            for pun in string.punctuation:\n",
    "                word = word.replace(pun, \"\")\n",
    "            if word not in self.stopWords:\n",
    "                words.append(word)\n",
    "        return words\n",
    "    \n",
    "    #Converts sentences into words\n",
    "    def __getWords__(self, sentences):\n",
    "        words = []\n",
    "        for sentence in sentences:\n",
    "            words += self.__clean__(sentence)\n",
    "        return words\n",
    "    \n",
    "    #returns the count of each word\n",
    "    def __getCount__(self, words):\n",
    "        count = {}\n",
    "        for word in words:\n",
    "            if word not in count:\n",
    "                count[word] = 0\n",
    "            count[word] += 1\n",
    "        return count\n",
    "    \n",
    "    #returns the probability of each word\n",
    "    def __getProb__(self, count):\n",
    "        prob = {}\n",
    "        n = len(count)\n",
    "        for i, v in count.items():\n",
    "            prob[i] = (v + self.alpha) / n\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d765553c",
   "metadata": {},
   "source": [
    "## Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e38d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "656a21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainSH, trainJA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "568ed634",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = testSH + testJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca6980de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384e08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get labels for the test data\n",
    "flag = 1\n",
    "labels = []\n",
    "for i in range(len(testData)):\n",
    "    if i == len(testData) / 2:\n",
    "        flag = 0\n",
    "    labels.append(flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf5487",
   "metadata": {},
   "source": [
    "## Checking the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e5638b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75      1000\n",
      "           1       0.97      0.36      0.53      1000\n",
      "\n",
      "    accuracy                           0.68      2000\n",
      "   macro avg       0.79      0.68      0.64      2000\n",
      "weighted avg       0.79      0.68      0.64      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377269a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
